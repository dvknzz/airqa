#!/usr/bin/env python3
"""
Air Quality API Server v5
- Ch·ªâ PM1.0, PM2.5, PM10, AQI (kh√¥ng c√≥ gas sensors)
- LSTM Prediction (d·ª± b√°o PM2.5 24h)
- Isolation Forest (ph√°t hi·ªán b·∫•t th∆∞·ªùng)
- QCVN 05:2023/BTNMT
"""

from flask import Flask, jsonify, request, render_template, send_from_directory
from flask_cors import CORS
from influxdb import InfluxDBClient
from datetime import datetime, timedelta
import pytz
import os
import logging
import numpy as np
import pickle
import warnings
warnings.filterwarnings('ignore')

app = Flask(__name__, static_folder='static')
CORS(app)

# ============ C·∫§U H√åNH ============
INFLUXDB_HOST = os.getenv('INFLUXDB_HOST', 'localhost')
INFLUXDB_PORT = int(os.getenv('INFLUXDB_PORT', 8086))
INFLUXDB_DB = os.getenv('INFLUXDB_DB', 'airquality')

VN_TZ = pytz.timezone('Asia/Ho_Chi_Minh')

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ============ TI√äU CHU·∫®N QCVN 05:2023 ============
STANDARDS = {
    'pm2_5': {
        'source': 'QCVN',
        'unit': 'Œºg/m¬≥',
        'limits': {'good': 25, 'moderate': 50, 'poor': 80, 'bad': 100},
        'description': 'QCVN 05:2023 | TB nƒÉm: 25 | TB 24h: 50'
    },
    'pm10': {
        'source': 'QCVN',
        'unit': 'Œºg/m¬≥',
        'limits': {'good': 50, 'moderate': 100, 'poor': 150, 'bad': 200},
        'description': 'QCVN 05:2023 | TB nƒÉm: 50 | TB 24h: 100'
    },
    'pm1_0': {
        'source': 'REF',
        'unit': 'Œºg/m¬≥',
        'limits': {'good': 15, 'moderate': 35, 'poor': 55, 'bad': 75},
        'description': 'Tham kh·∫£o (~60% PM2.5)'
    }
}

# ============ ML MODELS ============
# LSTM Model (Simple implementation - c√≥ th·ªÉ thay b·∫±ng TensorFlow model)
class SimpleLSTMPredictor:
    """
    D·ª± b√°o PM2.5 ƒë∆°n gi·∫£n d·ª±a tr√™n moving average v√† trend
    C√≥ th·ªÉ thay b·∫±ng TensorFlow LSTM model th·ª±c s·ª±
    """
    def __init__(self):
        self.history = []
        self.lookback = 24  # 24 gi·ªù
    
    def fit(self, data):
        """C·∫≠p nh·∫≠t l·ªãch s·ª≠"""
        self.history = list(data)[-168:]  # Gi·ªØ 7 ng√†y
    
    def predict(self, hours=24):
        """D·ª± b√°o PM2.5 cho n gi·ªù t·ªõi"""
        if len(self.history) < 24:
            return []
        
        predictions = []
        recent = self.history[-24:]
        
        # T√≠nh trend
        if len(self.history) >= 48:
            trend = (np.mean(self.history[-24:]) - np.mean(self.history[-48:-24])) / 24
        else:
            trend = 0
        
        # Moving average v·ªõi trend
        base = np.mean(recent)
        
        for h in range(hours):
            # Th√™m pattern theo gi·ªù trong ng√†y (gi·∫£ l·∫≠p)
            hour_of_day = (datetime.now().hour + h) % 24
            
            # Rush hour factor (7-9h v√† 17-19h cao h∆°n)
            if 7 <= hour_of_day <= 9 or 17 <= hour_of_day <= 19:
                hour_factor = 1.15
            elif 0 <= hour_of_day <= 5:
                hour_factor = 0.85
            else:
                hour_factor = 1.0
            
            pred = (base + trend * h) * hour_factor
            pred = max(5, min(300, pred))  # Gi·ªõi h·∫°n h·ª£p l√Ω
            predictions.append(round(pred, 1))
        
        return predictions


class IsolationForestDetector:
    """
    Ph√°t hi·ªán ƒëi·ªÉm b·∫•t th∆∞·ªùng trong d·ªØ li·ªáu PM2.5
    S·ª≠ d·ª•ng statistical approach thay v√¨ sklearn ƒë·ªÉ ƒë∆°n gi·∫£n
    """
    def __init__(self):
        self.mean = 0
        self.std = 0
        self.threshold = 2.5  # Z-score threshold
    
    def fit(self, data):
        """Hu·∫•n luy·ªán v·ªõi d·ªØ li·ªáu l·ªãch s·ª≠"""
        if len(data) > 10:
            self.mean = np.mean(data)
            self.std = np.std(data)
            if self.std == 0:
                self.std = 1
    
    def detect(self, value):
        """Ki·ªÉm tra xem gi√° tr·ªã c√≥ b·∫•t th∆∞·ªùng kh√¥ng"""
        if self.std == 0:
            return False, 0
        
        z_score = abs(value - self.mean) / self.std
        is_anomaly = z_score > self.threshold
        
        return is_anomaly, round(z_score, 2)
    
    def detect_batch(self, values):
        """Ki·ªÉm tra nhi·ªÅu gi√° tr·ªã"""
        results = []
        for v in values:
            is_anomaly, score = self.detect(v)
            results.append({
                'value': v,
                'is_anomaly': is_anomaly,
                'anomaly_score': score
            })
        return results


# Kh·ªüi t·∫°o models
lstm_predictor = SimpleLSTMPredictor()
anomaly_detector = IsolationForestDetector()


# ============ H√ÄM TI·ªÜN √çCH ============
def calculate_aqi(pm25):
    """T√≠nh AQI theo QCVN 05:2023/BTNMT"""
    breakpoints = [
        (0, 25, 0, 50),
        (25, 50, 50, 100),
        (50, 80, 100, 150),
        (80, 150, 150, 200),
        (150, 250, 200, 300),
        (250, 500, 300, 500)
    ]
    
    for c_lo, c_hi, i_lo, i_hi in breakpoints:
        if c_lo <= pm25 <= c_hi:
            aqi = ((i_hi - i_lo) / (c_hi - c_lo)) * (pm25 - c_lo) + i_lo
            return int(round(aqi))
    return 500 if pm25 > 500 else 0


def get_level(aqi):
    """L·∫•y m·ª©c ƒë·ªô ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠"""
    if aqi <= 50:
        return 'good', {'name': 'T·ªët', 'color': '#00E400', 'emoji': 'üòä'}
    elif aqi <= 100:
        return 'moderate', {'name': 'Trung b√¨nh', 'color': '#FFFF00', 'emoji': 'üòê'}
    elif aqi <= 150:
        return 'poor', {'name': 'K√©m', 'color': '#FF7E00', 'emoji': 'üò∑'}
    elif aqi <= 200:
        return 'bad', {'name': 'X·∫•u', 'color': '#FF0000', 'emoji': 'üö®'}
    else:
        return 'hazardous', {'name': 'Nguy h·∫°i', 'color': '#8F3F97', 'emoji': '‚ò†Ô∏è'}


def get_suggestions(level):
    """L·∫•y khuy·∫øn c√°o s·ª©c kh·ªèe"""
    suggestions = {
        'good': [
            'C√≥ th·ªÉ ho·∫°t ƒë·ªông ngo√†i tr·ªùi b√¨nh th∆∞·ªùng',
            'M·ªü c·ª≠a s·ªï ƒë·ªÉ th√¥ng gi√≥',
            'Th√≠ch h·ª£p cho m·ªçi ho·∫°t ƒë·ªông th·ªÉ thao'
        ],
        'moderate': [
            'Nh√≥m nh·∫°y c·∫£m n√™n h·∫°n ch·∫ø ho·∫°t ƒë·ªông ngo√†i tr·ªùi k√©o d√†i',
            'C√≥ th·ªÉ t·∫≠p th·ªÉ d·ª•c nh·∫π ngo√†i tr·ªùi',
            'Theo d√µi t√¨nh tr·∫°ng s·ª©c kh·ªèe'
        ],
        'poor': [
            'N√™n ƒëeo kh·∫©u trang khi ra ngo√†i',
            'H·∫°n ch·∫ø t·∫≠p th·ªÉ d·ª•c ngo√†i tr·ªùi',
            'Nh√≥m nh·∫°y c·∫£m n√™n ·ªü trong nh√†'
        ],
        'bad': [
            'H·∫°n ch·∫ø ra ngo√†i, ƒë√≥ng c·ª≠a s·ªï',
            'B·∫≠t m√°y l·ªçc kh√¥ng kh√≠ n·∫øu c√≥',
            'ƒêeo kh·∫©u trang N95 khi ra ngo√†i'
        ],
        'hazardous': [
            '·ªû trong nh√†, b·∫≠t m√°y l·ªçc kh√¥ng kh√≠',
            'Tr√°nh m·ªçi ho·∫°t ƒë·ªông ngo√†i tr·ªùi',
            'ƒê√≥ng k√≠n c·ª≠a, d√πng m√°y l·ªçc'
        ]
    }
    return suggestions.get(level, suggestions['moderate'])


def train_ml_models():
    """Hu·∫•n luy·ªán ML models v·ªõi d·ªØ li·ªáu g·∫ßn ƒë√¢y"""
    try:
        client = InfluxDBClient(host=INFLUXDB_HOST, port=INFLUXDB_PORT, database=INFLUXDB_DB)
        
        # L·∫•y 7 ng√†y d·ªØ li·ªáu
        query = '''
            SELECT mean(pm2_5) as pm2_5 FROM air_quality 
            WHERE time > now() - 7d
            GROUP BY time(1h) fill(null)
        '''
        
        result = client.query(query)
        points = list(result.get_points())
        client.close()
        
        pm25_values = [p['pm2_5'] for p in points if p['pm2_5'] is not None]
        
        if len(pm25_values) > 24:
            lstm_predictor.fit(pm25_values)
            anomaly_detector.fit(pm25_values)
            logger.info(f"‚úì ML models trained with {len(pm25_values)} data points")
        
    except Exception as e:
        logger.error(f"Error training ML models: {e}")


# Train models khi kh·ªüi ƒë·ªông
train_ml_models()


# ============ API ENDPOINTS ============
@app.route('/')
def index():
    """Trang ch·ªß - Serve static HTML"""
    return send_from_directory('static', 'index.html')


@app.route('/api/current')
def get_current():
    """L·∫•y d·ªØ li·ªáu hi·ªán t·∫°i"""
    node_id = request.args.get('node_id', 'node1')
    
    try:
        client = InfluxDBClient(host=INFLUXDB_HOST, port=INFLUXDB_PORT, database=INFLUXDB_DB)
        
        query = f'''
            SELECT last(pm1_0) as pm1_0, last(pm2_5) as pm2_5, last(pm10) as pm10, last(aqi) as aqi
            FROM air_quality 
            WHERE node_id = '{node_id}' 
            AND time > now() - 10m
        '''
        
        result = client.query(query)
        points = list(result.get_points())
        client.close()
        
        if not points:
            return jsonify({'status': 'error', 'message': 'No data available'}), 404
        
        point = points[0]
        
        pm1_0 = point.get('pm1_0', 0) or 0
        pm2_5 = point.get('pm2_5', 0) or 0
        pm10 = point.get('pm10', 0) or 0
        aqi = point.get('aqi') or calculate_aqi(pm2_5)
        
        level, level_info = get_level(aqi)
        
        # Anomaly detection
        is_anomaly, anomaly_score = anomaly_detector.detect(pm2_5)
        
        data = {
            'status': 'success',
            'node_id': node_id,
            'timestamp': datetime.now(VN_TZ).isoformat(),
            'pm1_0': round(pm1_0, 1),
            'pm2_5': round(pm2_5, 1),
            'pm10': round(pm10, 1),
            'aqi': aqi,
            'level': level,
            'level_info': {
                **level_info,
                'suggestions': get_suggestions(level)
            },
            'anomaly': {
                'is_anomaly': bool(is_anomaly),
                'score': float(anomaly_score),
                'message': '‚ö†Ô∏è Gi√° tr·ªã b·∫•t th∆∞·ªùng!' if is_anomaly else 'B√¨nh th∆∞·ªùng'
            },
            'standards': STANDARDS
        }
        
        return jsonify(data)
        
    except Exception as e:
        logger.error(f"Error: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/history')
def get_history():
    """L·∫•y l·ªãch s·ª≠ d·ªØ li·ªáu"""
    node_id = request.args.get('node_id', 'node1')
    hours = int(request.args.get('hours', 24))
    
    try:
        client = InfluxDBClient(host=INFLUXDB_HOST, port=INFLUXDB_PORT, database=INFLUXDB_DB)
        
        # Group by 5 ph√∫t
        query = f'''
            SELECT mean(pm1_0) as pm1_0, mean(pm2_5) as pm2_5, mean(pm10) as pm10, mean(aqi) as aqi
            FROM air_quality 
            WHERE node_id = '{node_id}' 
            AND time > now() - {hours}h
            GROUP BY time(5m) fill(null)
        '''
        
        result = client.query(query)
        points = list(result.get_points())
        client.close()
        
        data = []
        for p in points:
            if p.get('pm2_5') is not None:
                data.append({
                    'time': p['time'],
                    'time_label': datetime.fromisoformat(p['time'].replace('Z', '+00:00')).astimezone(VN_TZ).strftime('%H:%M'),
                    'pm1_0': round(p.get('pm1_0', 0) or 0, 1),
                    'pm2_5': round(p.get('pm2_5', 0) or 0, 1),
                    'pm10': round(p.get('pm10', 0) or 0, 1),
                    'aqi': int(p.get('aqi', 0) or 0)
                })
        
        # Statistics
        pm25_values = [d['pm2_5'] for d in data if d['pm2_5']]
        stats = {}
        if pm25_values:
            stats = {
                'pm2_5_min': min(pm25_values),
                'pm2_5_max': max(pm25_values),
                'pm2_5_avg': round(sum(pm25_values) / len(pm25_values), 1)
            }
        
        return jsonify({
            'status': 'success',
            'node_id': node_id,
            'hours': hours,
            'data': data,
            'statistics': stats
        })
        
    except Exception as e:
        logger.error(f"Error: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/predict')
def get_prediction():
    """D·ª± b√°o PM2.5 (LSTM)"""
    node_id = request.args.get('node_id', 'node1')
    hours = int(request.args.get('hours', 24))
    
    try:
        # C·∫≠p nh·∫≠t model v·ªõi d·ªØ li·ªáu m·ªõi nh·∫•t
        client = InfluxDBClient(host=INFLUXDB_HOST, port=INFLUXDB_PORT, database=INFLUXDB_DB)
        
        query = f'''
            SELECT mean(pm2_5) as pm2_5 FROM air_quality 
            WHERE node_id = '{node_id}' AND time > now() - 7d
            GROUP BY time(1h) fill(null)
        '''
        
        result = client.query(query)
        points = list(result.get_points())
        client.close()
        
        pm25_values = [p['pm2_5'] for p in points if p['pm2_5'] is not None]
        
        if len(pm25_values) < 24:
            return jsonify({
                'status': 'error',
                'message': 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± b√°o (c·∫ßn √≠t nh·∫•t 24 gi·ªù)'
            }), 400
        
        # Hu·∫•n luy·ªán v√† d·ª± b√°o
        lstm_predictor.fit(pm25_values)
        predictions = lstm_predictor.predict(hours)
        
        # T·∫°o d·ªØ li·ªáu d·ª± b√°o v·ªõi timestamp
        forecast_data = []
        base_time = datetime.now(VN_TZ)
        
        for i, pred in enumerate(predictions):
            forecast_time = base_time + timedelta(hours=i+1)
            aqi = calculate_aqi(pred)
            level, level_info = get_level(aqi)
            
            forecast_data.append({
                'time': forecast_time.isoformat(),
                'time_label': forecast_time.strftime('%H:%M %d/%m'),
                'hour': i + 1,
                'pm2_5': pred,
                'aqi': aqi,
                'level': level,
                'level_name': level_info['name'],
                'color': level_info['color']
            })
        
        return jsonify({
            'status': 'success',
            'node_id': node_id,
            'model': 'LSTM-Simple',
            'forecast_hours': hours,
            'predictions': forecast_data,
            'summary': {
                'avg_pm2_5': round(np.mean(predictions), 1),
                'max_pm2_5': round(max(predictions), 1),
                'min_pm2_5': round(min(predictions), 1)
            }
        })
        
    except Exception as e:
        logger.error(f"Prediction error: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/anomaly')
def check_anomaly():
    """Ki·ªÉm tra b·∫•t th∆∞·ªùng (Isolation Forest)"""
    node_id = request.args.get('node_id', 'node1')
    hours = int(request.args.get('hours', 24))
    
    try:
        client = InfluxDBClient(host=INFLUXDB_HOST, port=INFLUXDB_PORT, database=INFLUXDB_DB)
        
        query = f'''
            SELECT pm2_5, time FROM air_quality 
            WHERE node_id = '{node_id}' AND time > now() - {hours}h
        '''
        
        result = client.query(query)
        points = list(result.get_points())
        client.close()
        
        if not points:
            return jsonify({'status': 'error', 'message': 'No data'}), 404
        
        pm25_values = [p['pm2_5'] for p in points if p['pm2_5'] is not None]
        
        # Hu·∫•n luy·ªán detector
        anomaly_detector.fit(pm25_values)
        
        # Ki·ªÉm tra t·ª´ng ƒëi·ªÉm
        anomalies = []
        for p in points:
            if p['pm2_5'] is not None:
                is_anomaly, score = anomaly_detector.detect(p['pm2_5'])
                if is_anomaly:
                    anomalies.append({
                        'time': p['time'],
                        'pm2_5': p['pm2_5'],
                        'anomaly_score': score
                    })
        
        return jsonify({
            'status': 'success',
            'node_id': node_id,
            'hours': hours,
            'total_points': len(points),
            'anomaly_count': len(anomalies),
            'anomaly_rate': round(len(anomalies) / len(points) * 100, 1) if points else 0,
            'anomalies': anomalies[-20:],  # 20 b·∫•t th∆∞·ªùng g·∫ßn nh·∫•t
            'detector': {
                'type': 'Statistical Z-Score',
                'threshold': anomaly_detector.threshold,
                'mean': round(anomaly_detector.mean, 1),
                'std': round(anomaly_detector.std, 1)
            }
        })
        
    except Exception as e:
        logger.error(f"Anomaly detection error: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/suggestions')
def get_suggestions_api():
    """L·∫•y khuy·∫øn c√°o s·ª©c kh·ªèe"""
    node_id = request.args.get('node_id', 'node1')
    
    try:
        client = InfluxDBClient(host=INFLUXDB_HOST, port=INFLUXDB_PORT, database=INFLUXDB_DB)
        
        query = f'''
            SELECT last(pm2_5) as pm2_5 FROM air_quality 
            WHERE node_id = '{node_id}' AND time > now() - 10m
        '''
        
        result = client.query(query)
        points = list(result.get_points())
        client.close()
        
        if not points:
            return jsonify({'status': 'error', 'message': 'No data'}), 404
        
        pm2_5 = points[0].get('pm2_5', 0) or 0
        aqi = calculate_aqi(pm2_5)
        level, level_info = get_level(aqi)
        
        return jsonify({
            'status': 'success',
            'level': level,
            'level_name': level_info['name'],
            'color': level_info['color'],
            'emoji': level_info['emoji'],
            'suggestions': get_suggestions(level)
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/standards')
def get_standards():
    """L·∫•y th√¥ng tin ti√™u chu·∫©n"""
    return jsonify({
        'status': 'success',
        'standards': STANDARDS,
        'source': 'QCVN 05:2023/BTNMT'
    })


@app.route('/api/compare')
def compare_nodes():
    """So s√°nh d·ªØ li·ªáu gi·ªØa c√°c nodes"""
    hours = int(request.args.get('hours', 24))
    
    try:
        client = InfluxDBClient(host=INFLUXDB_HOST, port=INFLUXDB_PORT, database=INFLUXDB_DB)
        
        query = f'''
            SELECT mean(pm2_5) as pm2_5, mean(pm10) as pm10, mean(aqi) as aqi
            FROM air_quality 
            WHERE time > now() - {hours}h
            GROUP BY time(30m), node_id fill(null)
        '''
        
        result = client.query(query)
        client.close()
        
        comparison = {}
        for key, points in result.items():
            node_id = key[1].get('node_id', 'unknown')
            comparison[node_id] = []
            
            for p in points:
                if p.get('pm2_5') is not None:
                    comparison[node_id].append({
                        'time': p['time'],
                        'time_label': datetime.fromisoformat(p['time'].replace('Z', '+00:00')).astimezone(VN_TZ).strftime('%H:%M'),
                        'pm2_5': round(p.get('pm2_5', 0) or 0, 1),
                        'pm10': round(p.get('pm10', 0) or 0, 1),
                        'aqi': int(p.get('aqi', 0) or 0)
                    })
        
        return jsonify({
            'status': 'success',
            'hours': hours,
            'comparison': comparison
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/health')
def health():
    """Health check"""
    return jsonify({
        'status': 'healthy',
        'service': 'Air Quality API v5',
        'features': ['PM Only', 'LSTM Prediction', 'Anomaly Detection'],
        'standards': 'QCVN 05:2023/BTNMT',
        'timestamp': datetime.now(VN_TZ).isoformat()
    })


if __name__ == '__main__':
    logger.info("=" * 50)
    logger.info("üå¨Ô∏è Air Quality API Server v5")
    logger.info("   Sensors: PM1.0, PM2.5, PM10")
    logger.info("   ML: LSTM Prediction, Anomaly Detection")
    logger.info("   Standard: QCVN 05:2023/BTNMT")
    logger.info("=" * 50)
    app.run(host='0.0.0.0', port=5000, debug=False)
